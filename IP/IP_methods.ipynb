{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c125fa40-875c-44b1-9c3e-bf03df088431",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "28224c04-2fae-43ed-9d6f-1b5d74bfdd1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "square_p = 20  #green square for trimming\n",
    "eps = 15 \n",
    "def trim_img(img, plot = False): #try rapid trim image algo\n",
    "    \"\"\"\n",
    "    Description: Crop the pram img to the environement space\n",
    "    \n",
    "    \"\"\"\n",
    "    ti = np.copy(img)\n",
    "    # find red squares\n",
    "    if plot: print(\"starting trimming img\")\n",
    "   \n",
    "    square = cv2.imread('IP/image/fond.png',cv2.IMREAD_COLOR)\n",
    "    #resize template\n",
    "    square = cv2.resize(square,(square_p,square_p))\n",
    "    \n",
    "    #for debug\n",
    "    if plot:\n",
    "        plt.imshow(square[:,:,::-1])\n",
    "        plt.show()\n",
    "        \n",
    "    res =  cv2.matchTemplate(img,square, cv2.TM_CCORR_NORMED)\n",
    "    \n",
    "    if plot:\n",
    "        plt.imshow(res[:,:])\n",
    "        plt.show()\n",
    "      \n",
    "    tresh = res[cv2.minMaxLoc(res)[3][1],cv2.minMaxLoc(res)[3][0]]\n",
    "    tresh = .98*tresh\n",
    "    \n",
    "    find = np.where(res>tresh)\n",
    "\n",
    "    minx = min(find[0])\n",
    "    maxx = max(find[0])\n",
    "    miny = min(find[1])\n",
    "    maxy = max(find[1])\n",
    "    ti = ti[minx-eps:maxx+eps,miny-eps:maxy+eps]    \n",
    "    # security check\n",
    "    if abs(maxx-minx) < 0.5*img.shape[0] or abs(maxy-miny) < 0.5*img.shape[1]:\n",
    "        print(\"WARNING: wrong trimming very likely\")\n",
    "        print(f\"maxx: {maxx}, minx: {minx}, maxy: {maxy}, miny: {miny}\")\n",
    "        ti = img\n",
    "    if plot: print(\"Trim finished\")\n",
    "    return ti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "895ab580-028d-4c5e-986c-94ecde0654d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "thymio_mask_front_size = 1 #real size of the thymio mask: one dim cause circle or square \n",
    "thymio_mask_back_size = 1\n",
    "def find_thymio(trim_img, plot = False):\n",
    "    \"\"\"\n",
    "    Find thymio robot pose on an already trimmed image. The function will return a ~random value if thymio is not present on the image.\n",
    "    \n",
    "    param:\n",
    "    -trim_img: the image trimmed, i.e. the map in image form.\n",
    "    \n",
    "    return: x,y,orientation\n",
    "    -postion of thymio [x,y]\n",
    "    -orientation of thymio: \n",
    "    \"\"\"\n",
    "    if plot: print(\"start finding thymio\")\n",
    "    world_size = (118.9,2*84.1)\n",
    "\n",
    "    \n",
    "    ti_shape = trim_img.shape\n",
    "    ratio = (ti_shape[0]/world_size[0]+ti_shape[1]/world_size[1])/2 \n",
    "    \n",
    "    mask_pixel_front = (int(ratio*thymio_mask_front_size),int(ratio*thymio_mask_front_size))\n",
    "    mask_pixel_back = (int(ratio*thymio_mask_back_size),int(ratio*thymio_mask_back_size))\n",
    "    template_front = cv2.imread('IP/image/cb.png',cv2.IMREAD_COLOR)\n",
    "    template_back = cv2.imread('IP/image/co.png',cv2.IMREAD_COLOR)\n",
    "    \n",
    "    #resize template\n",
    "    template_front = cv2.resize(template_front,(mask_pixel_front[1],mask_pixel_front[0]))\n",
    "    template_back = cv2.resize(template_back,(mask_pixel_back[1],mask_pixel_back[0]))\n",
    "    \n",
    "    res_front = cv2.matchTemplate(trim_img,template_front,cv2.TM_CCORR_NORMED)\n",
    "    res_back = cv2.matchTemplate(trim_img,template_back,cv2.TM_CCORR_NORMED)\n",
    "    \n",
    "    if plot: \n",
    "        plt.imshow(res_front[:,:])\n",
    "        plt.show()\n",
    "        plt.imshow(res_back[:,:])\n",
    "        plt.show()\n",
    "    \n",
    "    tresh_front = res_front[cv2.minMaxLoc(res_front)[3][1],cv2.minMaxLoc(res_front)[3][0]]\n",
    "    tresh_back = res_back[cv2.minMaxLoc(res_back)[3][1],cv2.minMaxLoc(res_back)[3][0]]\n",
    "\n",
    "    \n",
    "    w = template_front.shape[1]\n",
    "    h = template_front.shape[0]\n",
    "    front = np.array(np.where(res_front >= tresh_front)) \n",
    "    back = np.array(np.where(res_back >= tresh_back))\n",
    "   \n",
    "    \n",
    "    pt =  back + 2/7*(front-back)\n",
    "    pt = np.array([pt[1],pt[0]]).astype(int)\n",
    "    front = np.array([front[0]+w//2,front[1]+h//2])   \n",
    "    back = np.array([back[0]+w//2,back[1]+h//2])\n",
    "    \n",
    "    pos = back + 2/7*(front-back) #find hole of the thymio, empirical: 2/7 \n",
    "    #change to have origin en bas a gauche\n",
    "    pos = pos.astype(int)\n",
    "     \n",
    "    orientation = np.arctan2((front-back)[1][0],(front-back)[0][0])\n",
    "    if orientation < 0:  orientation += 2*np.pi #change to [0,2pi[\n",
    "    orientation = (orientation - np.pi/2)%(2*np.pi) #change to new axis\n",
    "    \n",
    "    if plot:\n",
    "       \n",
    "        plot_img = np.copy(trim_img)\n",
    "        \n",
    "        coord = (pt[0][0]+w,pt[1][0]+h)\n",
    "        #print(pos,coord)\n",
    "        cv2.rectangle(plot_img,(pt[0][0],pt[1][0]),coord,(0,0,255),10)\n",
    "        plt.imshow(plot_img[:,:,::-1])\n",
    "        plt.show()\n",
    "        print(\"finished finding thymio\")\n",
    "        \n",
    "    x = ti_shape[0]-pos[0][0]\n",
    "    y = pos[1][0]\n",
    "    return y,x, orientation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4db301ea-61c1-4240-af79-9e4a9500c1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def template_matching (img, template, approx_shape, r ,method = cv2.TM_CCOEFF_NORMED,verbose = False, plot = False, intensity = 0.6):\n",
    "    \"\"\"\n",
    "    Perform template matching algorithm on a given image with a given template. The approximate pixels shape of the template must be given for sucessful template matching.\n",
    "    \n",
    "    param img: image to match template\n",
    "    param template: image that defines the matching pattern to find in img\n",
    "    param approx_shape: approximate shape (in pixels) of template on the img\n",
    "    param r: sensisivity parameter to detect several templates; to tune\n",
    "    param intensity: sensivity paremeter to detect the template (avoid detecting noise if no template is present); to tune\n",
    "    param method: template matching method\n",
    "    \n",
    "    return img_labelled: binary image of same shape as img; 1 if this pixel contains the template, 0 otherwise\n",
    "    \n",
    "    \"\"\"\n",
    "    #resize template\n",
    "    template = cv2.resize(template,(approx_shape[1],approx_shape[0]))\n",
    "    #match\n",
    "    \n",
    "    \n",
    "    res = cv2.matchTemplate(img,template,method)\n",
    "    tresh = res[cv2.minMaxLoc(res)[3][1],cv2.minMaxLoc(res)[3][0]]\n",
    "    #print(tresh)\n",
    "    if tresh < intensity: #prevent finding from indexing noise when finding nothing\n",
    "        tresh = np.inf\n",
    "    tresh = tresh*r #to find multiple objects\n",
    "    loc = np.where(res >= tresh)\n",
    "    w = template.shape[1]\n",
    "    h = template.shape[0]\n",
    "    \n",
    "    img_labelled = np.zeros((img.shape[0],img.shape[1]))\n",
    "\n",
    "    if tresh == np.inf:\n",
    "        print(\"WARNING: template not detected\")\n",
    "        return img_labelled \n",
    "    else:\n",
    "        if plot:\n",
    "            plt.imshow(res[:,:])\n",
    "            plt.show()\n",
    "            new_img = np.copy(img)\n",
    "        S = len(loc[0])\n",
    "        for pt in zip(*loc[::-1]):\n",
    "            coord = (pt[0]+w,pt[1]+h)\n",
    "            if plot:\n",
    "                cv2.rectangle(new_img,pt,coord,(0,0,255),2)\n",
    "            for i in range(pt[1],coord[1]): #draw rectangle\n",
    "                for j in range(pt[0],coord[0]):\n",
    "                    img_labelled[i,j] = 1\n",
    "\n",
    "\n",
    "        if plot:\n",
    "            plt.imshow(new_img[:,:,::-1])\n",
    "            plt.show()\n",
    "        return img_labelled \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "599f945a-8b0d-4b33-b01d-0932716c8beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## usefull functions: \n",
    "def defWorldSize (img):\n",
    "    s = img.shape\n",
    "    hor = (118.9,2*84.1) #double A0 format\n",
    "    ver = (2*84.1,118.9) \n",
    "    if s[0] > s[1]:\n",
    "        return ver, cv2.rotate(img,cv2.ROTATE_90_CLOCKWISE)\n",
    "    else:\n",
    "        return hor,img\n",
    "\n",
    "#could optimize for several OR at the time, \n",
    "#but no need as it is already very fast with low resolution img \n",
    "def OR (matrix1, matrix2):\n",
    "    m = np.zeros(matrix1.shape)\n",
    "    for i in range(matrix1.shape[0]):\n",
    "        for j in range(matrix1.shape[1]):\n",
    "            if matrix1[i,j] or matrix2[i,j]: m[i,j]=1\n",
    "    return m\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50f18267-b1a6-403c-ba37-01ce137948e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline_IP(plot = False):\n",
    "    \"\"\"\n",
    "    !! need the image folder in the same directory !!\n",
    "    Description:\n",
    "    runs the whole pipeline to build the map of the environement. \n",
    "    Performs global image analysis for our mobile project task: Basics of mobile robotics, MICRO-452.\n",
    "    \n",
    "    param plot: show graphs and information on where the program holds\n",
    "    \n",
    "    return: \n",
    "    1) multiple matrix with the same shape as the img param / 10 (in 2D) in the output folder:\n",
    "        roads: matrix with roads labelled by 1, 0 otherwise\n",
    "        passage: matrix with crossroads labelled by 1, \"\n",
    "        goal: \"          target labelled by 1\n",
    "        obst: matrix with roads labbelled by a 1, but with the location of the crossroads removed if they overlap\n",
    "    2) (x,y), orientation: x, y postion of the thymio robot in the world and its orientation\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    img = cv2.imread('img.jpg',cv2.IMREAD_COLOR)\n",
    "    world_size,img = defWorldSize(img)\n",
    "\n",
    "    reducer = 10\n",
    "    desiredMapShape = (img.shape[0]//reducer,img.shape[1]//reducer)\n",
    "    \n",
    "    if plot:\n",
    "        plt.imshow(img[:,:,::-1])\n",
    "        plt.show()\n",
    "        \n",
    "    ### objects real size\n",
    "    road_real_size_a = (12.5,12.5)\n",
    "    road_real_size_s = (6,12.5)\n",
    "    passage_real_size_s = (14,14) \n",
    "    goal_real_size = (2,2) ##change goal\n",
    "\n",
    "\n",
    "    ### tresholds // can go change them manually\n",
    "    #square_tresh = .99\n",
    "    road_angle_tresh = .999\n",
    "    road_straigth_tresh = .99\n",
    "    passage_tresh = .97\n",
    "    \n",
    "    ###trim the img\n",
    "    ti = trim_img(img,plot = plot) \n",
    "    ti_pixels = ti.shape\n",
    "    if plot: \n",
    "        plt.imshow(ti[:,:,::-1])\n",
    "        plt.show()\n",
    "    ratio = (ti_pixels[0]/world_size[0]+ti_pixels[1]/world_size[1])/2\n",
    "    \n",
    "    ###find thymio pose in high resolution\n",
    "    x,y,orientation = find_thymio(ti,plot)\n",
    "    x = int(x/ti_pixels[1]*desiredMapShape[1]) #convert to the coord of the desired output map shape\n",
    "    y = int(y/ti_pixels[0]*desiredMapShape[0])\n",
    "    \n",
    "    ###find goal \n",
    "    if plot: print(\"start detecting target position\")\n",
    "    goal_img = cv2.imread('IP/image/goal.jpg',cv2.IMREAD_COLOR)   \n",
    "    goal_pixel = (int(ratio*goal_real_size[0]),int(ratio*goal_real_size[1])) \n",
    "    #filtered_img = ti - cv2.GaussianBlur(ti, (0,0), 3) \n",
    "    matchgoal = template_matching(ti,goal_img,goal_pixel,r=1,plot = plot, verbose = plot,method = cv2.TM_CCORR_NORMED)\n",
    "    #matchgoal2 = template_matching(filtered_img,cv2.rotate(goal_img,cv2.ROTATE_90_CLOCKWISE),(goal_pixel[1],goal_pixel[0]),r=1,plot = plot, verbose = plot,method = cv2.TM_CCORR_NORMED,intensity = .4)\n",
    "    #matchgoal3 = template_matching(filtered_img,cv2.rotate(goal_img,cv2.ROTATE_90_COUNTERCLOCKWISE),(goal_pixel[1],goal_pixel[0]),r=1,plot = plot, verbose = plot,method = cv2.TM_CCORR_NORMED,intensity = .4)\n",
    "    #matchgoal4 = template_matching(filtered_img,cv2.rotate(goal_img,cv2.ROTATE_180),goal_pixel,r=1,plot = plot, verbose = plot,method = cv2.TM_CCORR_NORMED,intensity = .4)\n",
    "    #matchgoal = OR(OR(matchgoal3,matchgoal4),OR(matchgoal1,matchgoal2))\n",
    "    if plot:\n",
    "        plt.imshow(matchgoal[:,:])\n",
    "        plt.show()\n",
    "        print(\"finish detecting target\")\n",
    "    \n",
    "    \n",
    "    ###reduce resolution to decrease computation\n",
    "    ti = cv2.resize(ti,(desiredMapShape[1],desiredMapShape[0]))\n",
    "    ratio = (desiredMapShape[0]/world_size[0]+desiredMapShape[1]/world_size[1])/2 #estimate ratio: pixels/cm \n",
    "    if plot:\n",
    "        plt.imshow(ti[:,:,::-1])\n",
    "        plt.show()\n",
    "\n",
    "    ###find roads \n",
    "    road_a =cv2.imread('IP/image/road_angle.png',cv2.IMREAD_COLOR)\n",
    "    road_s = cv2.imread('IP/image/road_straight.png',cv2.IMREAD_COLOR)\n",
    "    road_pixels_a = (int(ratio*road_real_size_a[0]),int(ratio*road_real_size_a[1]))\n",
    "    road_pixels_s = (int(ratio*road_real_size_s[0]),int(ratio*road_real_size_s[1]))\n",
    "    \n",
    "    if plot: print(\"start detecting edge roads\")\n",
    "    match1 = template_matching(ti,road_a,road_pixels_a,road_angle_tresh, verbose = plot,method = cv2.TM_CCORR_NORMED, plot = plot)\n",
    "    match2= template_matching(ti,cv2.rotate(road_a,cv2.ROTATE_90_CLOCKWISE),(road_pixels_a[1],road_pixels_a[0]),road_angle_tresh,method = cv2.TM_CCORR_NORMED, verbose = plot, plot = plot)\n",
    "    match3 = template_matching(ti,cv2.rotate(road_a,cv2.ROTATE_180),road_pixels_a,road_angle_tresh, verbose = plot,method = cv2.TM_CCORR_NORMED, plot = plot)\n",
    "    match4 = template_matching(ti,cv2.rotate(road_a,cv2.ROTATE_90_COUNTERCLOCKWISE),(road_pixels_a[1],road_pixels_a[0]),road_angle_tresh,verbose = plot,method = cv2.TM_CCORR_NORMED, plot = plot) \n",
    "    if plot: print(\"start detecting straigth roads\")\n",
    "    match5 = template_matching(ti,road_s,road_pixels_s,road_straigth_tresh, verbose = plot, method = cv2.TM_CCORR_NORMED,plot = plot)\n",
    "    match6 = template_matching(ti,cv2.rotate(road_s,cv2.ROTATE_90_CLOCKWISE),(road_pixels_s[1],road_pixels_s[0]),road_straigth_tresh,method = cv2.TM_CCORR_NORMED, verbose = plot, plot = plot)\n",
    "    \n",
    "    result_r = OR(OR(OR(OR(OR(match1,match2),match3),match4),match5),match6) \n",
    "    if plot: \n",
    "        plt.imshow(result_r[:,:])\n",
    "        plt.show()\n",
    "        print(\"finish detecting roads\")\n",
    "    \n",
    "    ###find crossroads\n",
    "    if plot: print(\"start detecting crossroads\")\n",
    "    passage_img = cv2.imread('IP/image/passage.png',cv2.IMREAD_COLOR)   \n",
    "    passage_pixels=(int(ratio*passage_real_size_s[0]),int(ratio*passage_real_size_s[1]))\n",
    "    match7 = template_matching(ti,passage_img,passage_pixels,passage_tresh, plot = plot, verbose = plot,intensity = .1,)\n",
    "    match8 = template_matching(ti,cv2.rotate(passage_img,cv2.ROTATE_90_CLOCKWISE),(passage_pixels[1],passage_pixels[0]),passage_tresh,intensity = .1, plot = plot, verbose = plot)\n",
    "\n",
    "    result_p = OR(match7,match8)\n",
    "    if plot:\n",
    "        plt.imshow(result_p[:,:])\n",
    "        plt.show()\n",
    "        print(\"finish detecting cross roads\")\n",
    "    \n",
    "    #treat cross roads and roads \n",
    "    result_o = np.zeros(result_p.shape)\n",
    "    for i in range(result_p.shape[0]):\n",
    "        for j in range(result_p.shape[1]):\n",
    "            if result_p[i,j] and result_r[i,j]:\n",
    "                result_o[i,j] = 0;\n",
    "            elif result_r[i,j]:\n",
    "                result_o[i,j] = 1;\n",
    "    if plot:\n",
    "        plt.imshow(result_o[:,:])\n",
    "        plt.show()\n",
    "       \n",
    "    with open('output/roads.csv', 'w', encoding='UTF8', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "\n",
    "        # write multiple rows\n",
    "        writer.writerows(result_r)\n",
    "    \n",
    "    with open('output/passage.csv', 'w', encoding='UTF8', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "\n",
    "        # write multiple rows\n",
    "        writer.writerows(result_p)\n",
    "    with open('output/obst.csv', 'w', encoding='UTF8', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "\n",
    "        # write multiple rows\n",
    "        writer.writerows(result_o)\n",
    " \n",
    "    with open('output/goal.csv', 'w', encoding='UTF8', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "\n",
    "        # write multiple rows\n",
    "        writer.writerows(matchgoal)\n",
    "        \n",
    "    \n",
    "    if plot: print(\"Image Processing finished in %s seconds \" % (time.time() - start_time))\n",
    "    \n",
    "    return (x,y), orientation\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8837a05c-22e1-433c-a820-59f4c6ff745d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pipeline_IP(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be94a897-848f-4b11-8f3d-2a3931fe1a52",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
